{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import string\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 10000 \"parallel sentences will be loaded (original sentence + its translation)\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## 9000 \"parallel sentences\" will be used to train the model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## 1000 \"parallel sentences\" will be used to test the model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_sentences = 10000\n",
    "\n",
    "dataset = pd.read_csv('./eng_-french.csv/eng_-french.csv')\n",
    "\n",
    "test_proportion = 0.1\n",
    "train_test_threshold = int((1-test_proportion)*total_sentences)\n",
    "\n",
    "printmd(f'## {total_sentences} \"parallel sentences will be loaded (original sentence + its translation)\"')\n",
    "printmd(f'## {train_test_threshold} \"parallel sentences\" will be used to train the model')\n",
    "printmd(f'## {total_sentences-train_test_threshold} \"parallel sentences\" will be used to test the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35664</th>\n",
       "      <td>I want to go to Mars.</td>\n",
       "      <td>Je veux me rendre sur Mars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11476</th>\n",
       "      <td>I'm not patient.</td>\n",
       "      <td>Je ne suis pas patient.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>We'll never know.</td>\n",
       "      <td>Nous ne le saurons jamais.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21719</th>\n",
       "      <td>We've made a deal.</td>\n",
       "      <td>Nous avons passé un accord.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60740</th>\n",
       "      <td>I bought a book of jokes.</td>\n",
       "      <td>J'ai acheté un livre de blagues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87850</th>\n",
       "      <td>Are you sure it's impossible?</td>\n",
       "      <td>Êtes-vous sûres que c'est impossible ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56665</th>\n",
       "      <td>That dog is really ugly.</td>\n",
       "      <td>Ce chien est vraiment laid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169395</th>\n",
       "      <td>Quite a few people were present at the meeting...</td>\n",
       "      <td>Pas mal de gens étaient présents à la réunion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80458</th>\n",
       "      <td>You like Boston, don't you?</td>\n",
       "      <td>Tu aimes Boston, pas vrai ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161969</th>\n",
       "      <td>I don't think we should be talking to each other.</td>\n",
       "      <td>Je ne pense pas que nous devrions nous parler.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English words/sentences  \\\n",
       "35664                               I want to go to Mars.   \n",
       "11476                                    I'm not patient.   \n",
       "16900                                   We'll never know.   \n",
       "21719                                  We've made a deal.   \n",
       "60740                           I bought a book of jokes.   \n",
       "87850                       Are you sure it's impossible?   \n",
       "56665                            That dog is really ugly.   \n",
       "169395  Quite a few people were present at the meeting...   \n",
       "80458                         You like Boston, don't you?   \n",
       "161969  I don't think we should be talking to each other.   \n",
       "\n",
       "                                   French words/sentences  \n",
       "35664                         Je veux me rendre sur Mars.  \n",
       "11476                             Je ne suis pas patient.  \n",
       "16900                          Nous ne le saurons jamais.  \n",
       "21719                         Nous avons passé un accord.  \n",
       "60740                    J'ai acheté un livre de blagues.  \n",
       "87850              Êtes-vous sûres que c'est impossible ?  \n",
       "56665                         Ce chien est vraiment laid.  \n",
       "169395  Pas mal de gens étaient présents à la réunion ...  \n",
       "80458                         Tu aimes Boston, pas vrai ?  \n",
       "161969     Je ne pense pas que nous devrions nous parler.  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(frac = 1, random_state = 0)\n",
    "dataset.iloc[1000:1010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to go to mars</td>\n",
       "      <td>je veux me rendre sur mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i m not patient</td>\n",
       "      <td>je ne suis pas patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we ll never know</td>\n",
       "      <td>nous ne le saurons jamais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we ve made a deal</td>\n",
       "      <td>nous avons passé un accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i bought a book of jokes</td>\n",
       "      <td>j ai acheté un livre de blagues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>are you sure it s impossible</td>\n",
       "      <td>êtes vous sûres que c est impossible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that dog is really ugly</td>\n",
       "      <td>ce chien est vraiment laid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quite a few people were present at the meeting...</td>\n",
       "      <td>pas mal de gens étaient présents à la réunion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>you like boston don t you</td>\n",
       "      <td>tu aimes boston pas vrai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i don t think we should be talking to each other</td>\n",
       "      <td>je ne pense pas que nous devrions nous parler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                               i want to go to mars   \n",
       "1                                    i m not patient   \n",
       "2                                   we ll never know   \n",
       "3                                  we ve made a deal   \n",
       "4                           i bought a book of jokes   \n",
       "5                       are you sure it s impossible   \n",
       "6                            that dog is really ugly   \n",
       "7  quite a few people were present at the meeting...   \n",
       "8                          you like boston don t you   \n",
       "9   i don t think we should be talking to each other   \n",
       "\n",
       "                                                   1  \n",
       "0                         je veux me rendre sur mars  \n",
       "1                             je ne suis pas patient  \n",
       "2                          nous ne le saurons jamais  \n",
       "3                         nous avons passé un accord  \n",
       "4                    j ai acheté un livre de blagues  \n",
       "5               êtes vous sûres que c est impossible  \n",
       "6                         ce chien est vraiment laid  \n",
       "7  pas mal de gens étaient présents à la réunion ...  \n",
       "8                           tu aimes boston pas vrai  \n",
       "9      je ne pense pas que nous devrions nous parler  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(string):\n",
    "    string = string.replace(\"\\u202f\",\" \")\n",
    "    string = string.lower()\n",
    "\n",
    "    for p in punctuation + \"«»\" + \"0123456789\":\n",
    "        string = string.replace(p,\" \")\n",
    "\n",
    "    string = re.sub('\\s+',' ',string)\n",
    "    string = string.strip()\n",
    "\n",
    "    return string\n",
    "\n",
    "dataset[\"English words/sentences\"] = dataset[\"English words/sentences\"].apply(lambda x: clean(x))\n",
    "dataset[\"French words/sentences\"] = dataset[\"French words/sentences\"].apply(lambda x: clean(x))\n",
    "\n",
    "dataset = dataset.values\n",
    "dataset = dataset[:total_sentences]\n",
    "\n",
    "train, test = dataset[:train_test_threshold], dataset[train_test_threshold:]\n",
    "\n",
    "source_str, target_str = \"French\", \"English\"\n",
    "\n",
    "idx_src, idx_tar = 1, 0\n",
    "pd.DataFrame(dataset[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Target (English) Vocabulary Size: 4644"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Target (English) Max Length: 39"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Source (French) Vocabulary Size: 6708"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Source (French) Max Length: 50\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def max_len(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "\n",
    "def encode_sequences(tokenizer,length,lines):\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    X = pad_sequences(X, maxlen=length,padding='post')\n",
    "    return X\n",
    "\n",
    "def encode_output(sequences,vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence,num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = np.array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "\n",
    "tar_tokenizer = create_tokenizer(dataset[:,idx_tar])\n",
    "tar_vocab_size = len(tar_tokenizer.word_index)+1\n",
    "tar_length = max_len(dataset[:, idx_tar])\n",
    "printmd(f'\\nTarget ({target_str}) Vocabulary Size: {tar_vocab_size}')\n",
    "printmd(f\"Target ({target_str}) Max Length: {tar_length}\")\n",
    "\n",
    "src_tokenizer = create_tokenizer(dataset[:,idx_src])\n",
    "src_vocab_size = len(src_tokenizer.word_index)+1\n",
    "src_length = max_len(dataset[:, idx_src])\n",
    "printmd(f'\\nSource ({source_str}) Vocabulary Size: {src_vocab_size}')\n",
    "printmd(f'Source ({source_str}) Max Length: {src_length}\\n')\n",
    "\n",
    "trainX = encode_sequences(src_tokenizer,src_length,train[:,idx_src])\n",
    "trainY = encode_sequences(tar_tokenizer,tar_length,train[:,idx_tar])\n",
    "trainY = encode_output(trainY,tar_vocab_size)\n",
    "\n",
    "testX = encode_sequences(src_tokenizer,src_length,test[:, idx_src])\n",
    "testY = encode_sequences(tar_tokenizer, tar_length, test[:, idx_tar])\n",
    "testY = encode_output(testY, tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.8843 - val_loss: 1.1606\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 191s 2s/step - loss: 1.1399 - val_loss: 1.1408\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 243s 2s/step - loss: 1.1381 - val_loss: 1.1752\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 250s 2s/step - loss: 1.0539 - val_loss: 1.0604\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 239s 2s/step - loss: 1.0168 - val_loss: 1.0586\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 248s 2s/step - loss: 1.0048 - val_loss: 1.0541\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 244s 2s/step - loss: 0.9973 - val_loss: 1.0553\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 241s 2s/step - loss: 0.9873 - val_loss: 1.0541\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 248s 2s/step - loss: 0.9807 - val_loss: 1.0626\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 243s 2s/step - loss: 0.9743 - val_loss: 1.0594\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 245s 2s/step - loss: 0.9676 - val_loss: 1.0576\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 252s 2s/step - loss: 0.9615 - val_loss: 1.0632\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 265s 2s/step - loss: 0.9560 - val_loss: 1.0636\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 251s 2s/step - loss: 0.9504 - val_loss: 1.0607\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 242s 2s/step - loss: 0.9446 - val_loss: 1.0643\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 245s 2s/step - loss: 0.9377 - val_loss: 1.0584\n"
     ]
    }
   ],
   "source": [
    "def create_model(src_vocab ,tar_vocab, src_timestamps, tar_timestamps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timestamps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timestamps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "\n",
    "model = create_model(src_vocab_size, tar_vocab_size, src_length, tar_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "history = model.fit(trainX,\n",
    "                    trainY,\n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=[\n",
    "                        EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            patience=10,\n",
    "                            restore_best_weights=True\n",
    "                        )\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Result on the Training Set ###\n",
      "FRENCH (Source)                ENGLISH (Target)          Automatic translation in ENGLISH\n",
      "\n",
      "nous changeons toutes          we all change             i you\n",
      "je ne suis pas cynique à ce point là i m not that cynical      i you you to\n",
      "j aimerais te dire quelque chose en privé i d like to tell you something in private i you you to to to\n",
      "le restaurant était loin de la gare the restaurant was far from the train station i you you to to\n",
      "tom ne sait pas où marie a l habitude d aller skier tom doesn t know where mary usually goes skiing i you you to to to to\n",
      "je ne veux pas perdre mary     i don t want to lose mary i you you to to\n",
      "elle est partie                she went out              i you you\n",
      "quel est le nom de ton petit copain what s your boyfriend s name i you you to\n",
      "nous n allons pas arrêter maintenant we re not going to stop now i you you to to\n",
      "j étais insouciant             i was careless            i you\n",
      "je suis désolée d avoir raté ton anniversaire i m sorry i missed your birthday i you you to to\n",
      "je n ai pas réalisé que tu étais éveillée i didn t realize you were awake i you you to to\n",
      "tout va bien se passer         everything s going to be all right i you you to\n",
      "ne t en fais pas je suis muet comme une tombe don t worry my lips are sealed i you you to to\n",
      "vous êtes la personne la plus importante dans ma vie you are the most important person in my life i you you to to to to\n",
      "tu devrais aller chez nous maintenant you should go home now    i you you to to\n",
      "tu vas passer du très bon temps you ll have a wonderful time i you you to to to\n",
      "il n est pas tel qu il paraît  he is not like he seems   i you you to to\n",
      "je veux qu on me choie         i want to be pampered     i you you to\n",
      "seras tu encore là quand je vais revenir will you still be here when i get back i you you to to to to\n",
      "attendez je veux vous dire quelque chose wait i want to tell you something i you you to to\n",
      "\n",
      "\n",
      "### Result on the Test Set ###\n",
      "FRENCH (Source)                ENGLISH (Target)          Automatic translation in ENGLISH\n",
      "\n",
      "pourrais tu mettre à jour ces données pour moi could i get you to update this data for me i you you to to to\n",
      "vous êtes sympa                you re nice               i you\n",
      "tu n es pas forcé d y croire mais c est néanmoins la vérité you may not believe it but it is nonetheless true i you you to to to to to\n",
      "je ne me plains pas souvent    i don t complain often    i you you to\n",
      "je me sens mal à ce sujet      i feel bad about it       i you you\n",
      "prenez vous plaisir à votre week end are you enjoying your weekend i you you to\n",
      "je n ai pas eu beaucoup de sommeil i haven t had much sleep  i you you to to\n",
      "disposeriez vous de temps pour m aider à quelque chose would you have time to help me with something i you you to to to\n",
      "qu est ce qui t est arrivé hier soir what happened to you last night i you you to to\n",
      "je suis offensé                i m offended              i you\n",
      "êtes vous prêts à faire la fête are you ready to party    i you you to to\n",
      "je vous ai crues               i believed you            i you you\n",
      "puis je emprunter ceci pour un petit moment can i borrow this for a little while i you you to to to\n",
      "j imagine que c est la vôtre   i m guessing this is yours i you you\n",
      "le jazz fusion est un mélange de rock et de jazz jazz fusion is a combination of rock and jazz i you you to to to\n",
      "qu est ce que ça fait          how does it feel          i you you to\n",
      "ce matin nous avons eu une épaisse couche de givre we had a heavy frost this morning i you you to to to\n",
      "je me suis rendu à l aéroport en taxi i went to the airport by taxi i you you to to\n",
      "nous savons nous y prendre     we can handle that        i you you to\n",
      "étudies tu toujours le français are you still studying french i you you to\n",
      "il était blessé à l épaule     he was wounded in the shoulder i you you to\n"
     ]
    }
   ],
   "source": [
    "def word_for_id(integer,tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def predict_seq(model, tokenizer, source):\n",
    "    prediction = model.predict(source,verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)\n",
    "\n",
    "def compare_prediction(model, tokenizer, sources, raw_dataset, limit=20):\n",
    "    actual, predicted = [], []\n",
    "    src = f'{source_str.upper()} (Source)'\n",
    "    tgt = f'{target_str.upper()} (Target)'\n",
    "    pred = f'Automatic translation in {target_str.upper()}'\n",
    "    print(f'{src:30} {tgt:25} {pred}\\n')\n",
    "\n",
    "    for i, source in enumerate(sources):\n",
    "        source = source.reshape((1,source.shape[0]))\n",
    "        translation = predict_seq(model, tar_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        print(f'{raw_src:30} {raw_target:25} {translation}')\n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "print('### Result on the Training Set ###')\n",
    "compare_prediction(model, tar_tokenizer, trainX, train)\n",
    "\n",
    "# test on some test sequences\n",
    "print('\\n\\n### Result on the Test Set ###')\n",
    "compare_prediction(model, tar_tokenizer, testX, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abhij\\Desktop\\translate_project\\translator.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m bleu_dic\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m bleu_train \u001b[39m=\u001b[39m bleu_score(model, tar_tokenizer, trainX, train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m bleu_test \u001b[39m=\u001b[39m bleu_score(model, tar_tokenizer, testX, test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(x \u001b[39m=\u001b[39m bleu_train\u001b[39m.\u001b[39mkeys(), height \u001b[39m=\u001b[39m bleu_train\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mBLEU score with the training set\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\abhij\\Desktop\\translate_project\\translator.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, source \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sources):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     source \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m,source\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     translation \u001b[39m=\u001b[39m predict_seq(model, tar_tokenizer, source)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     raw_target, raw_src \u001b[39m=\u001b[39m raw_dataset[i]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     actual\u001b[39m.\u001b[39mappend([raw_target\u001b[39m.\u001b[39msplit()])\n",
      "\u001b[1;32mc:\\Users\\abhij\\Desktop\\translate_project\\translator.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_seq\u001b[39m(model, tokenizer, source):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(source,verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     integers \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margmax(vector) \u001b[39mfor\u001b[39;00m vector \u001b[39min\u001b[39;00m prediction]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/abhij/Desktop/translate_project/translator.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2631\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2629\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   2630\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2631\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2632\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2633\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    874\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 876\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    877\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[0;32m    878\u001b[0m )\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m    880\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\abhij\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def bleu_score(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = [], []\n",
    "    for i, source in enumerate(sources):\n",
    "        source = source.reshape((1,source.shape[0]))\n",
    "        translation = predict_seq(model, tar_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "\n",
    "    bleu_dic = {}\n",
    "    bleu_dic['1-grams'] = corpus_bleu(actual, predicted, weights=(1.0,0,0,0))\n",
    "    bleu_dic['1-2-grams'] = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
    "    bleu_dic['1-3-grams'] = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
    "    bleu_dic['1-4-grams'] = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "    return bleu_dic\n",
    "\n",
    "bleu_train = bleu_score(model, tar_tokenizer, trainX, train)\n",
    "bleu_test = bleu_score(model, tar_tokenizer, testX, test)\n",
    "\n",
    "plt.bar(x = bleu_train.keys(), height = bleu_train.values())\n",
    "plt.title(\"BLEU score with the training set\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = bleu_test.keys(), height = bleu_test.values())\n",
    "plt.title(\"BLEU Score with the test set\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
